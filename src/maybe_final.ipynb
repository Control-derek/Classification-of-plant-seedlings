{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from processer import equalize, zmIceColor, extractGreen\n",
    "datasets_path = \"..\\\\dataset\\\\classifer\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantSeedDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        PlantSeedDataset\n",
    "        :param data_dir: str, 数据集所在路径\n",
    "        :param transform: torch.transform, 数据预处理\n",
    "        \"\"\"\n",
    "        self.data_info = self.get_img_info(data_dir)  \n",
    "        self.transform = transform\n",
    "        self.name_dic = {'Black-grass': 0, 'Charlock': 1, 'Cleavers': 2, 'Common Chickweed': 3, \n",
    "                'Common wheat': 4, 'Fat Hen': 5, 'Loose Silky-bent': 6, 'Maize': 7,\n",
    "                'Scentless Mayweed': 8, 'Shepherds Purse': 9, 'Small-flowered Cranesbill': 10, 'Sugar beet': 11}\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        path_img, label, img_name = self.data_info[index]\n",
    "        img = Image.open(path_img).convert('RGB')     \n",
    " \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)   \n",
    "             \n",
    "        return img, label, img_name\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    " \n",
    "    @staticmethod\n",
    "    def get_img_info(data_dir):\n",
    "        data_info = list()\n",
    "        for root, dirs, _ in os.walk(data_dir):\n",
    "            for sub_dir in dirs:\n",
    "                img_names = os.listdir(os.path.join(root, sub_dir))\n",
    "                img_names = list(filter(lambda x: x.endswith('.png'), img_names))\n",
    " \n",
    "                for i in range(len(img_names)):\n",
    "                    img_name = img_names[i]\n",
    "                    path_img = os.path.join(root, sub_dir, img_name)\n",
    "                    label = sub_dir\n",
    "                    data_info.append((path_img, label, img_name))\n",
    " \n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        np.asarray,\n",
    "        transforms.Lambda(lambda x: cv2.cvtColor(x, cv2.COLOR_RGB2BGR))\n",
    "        ])\n",
    "dataset = PlantSeedDataset(datasets_path, transform=transform)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "def processer(img):\n",
    "    # 颜色增强\n",
    "    ace_img = zmIceColor(img/255.0, ratio=4, radius=3)\n",
    "    ace_img  = ace_img * 255\n",
    "    ace_img = np.uint8(ace_img)\n",
    "    # 抽绿色\n",
    "    gre_img = extractGreen(ace_img, 7)\n",
    "    return gre_img\n",
    "\n",
    "def SIFT(gre_img):\n",
    "    # 创建SIFT特征检测器\n",
    "    sift_after = cv2.SIFT_create()\n",
    "    # 特征点提取与描述子生成\n",
    "    kp, des = sift_after.detectAndCompute(gre_img, None)\n",
    "    return kp, des\n",
    "\n",
    "# 初始化BOW训练器\n",
    "def bow_init(feature_sift_list):\n",
    "    # 100类\n",
    "    bow_kmeans_trainer = cv2.BOWKMeansTrainer(100)\n",
    "    \n",
    "    for feature_sift in feature_sift_list:\n",
    "        if type(feature_sift) == type(None):\n",
    "            continue\n",
    "        # print(feature_sift.shape)\n",
    "        bow_kmeans_trainer.add(feature_sift)\n",
    "    \n",
    "    # 进行k-means聚类，返回词汇字典 也就是聚类中心\n",
    "    voc = bow_kmeans_trainer.cluster()\n",
    "    \n",
    "    # 输出词汇字典\n",
    "    # print(voc)\n",
    "    # print(type(voc),voc.shape)\n",
    "    \n",
    "    # FLANN匹配  \n",
    "    # algorithm用来指定匹配所使用的算法，可以选择的有LinearIndex、KTreeIndex、KMeansIndex、CompositeIndex和AutotuneInde\n",
    "    # 这里选择的是KTreeIndex(使用kd树实现最近邻搜索)\n",
    "    flann_params = dict(algorithm=1,tree=5)\n",
    "    flann = cv2.FlannBasedMatcher(flann_params,{})\n",
    "    \n",
    "    # print(flann)\n",
    "    \n",
    "    #初始化bow提取器(设置词汇字典),用于提取每一张图像的BOW特征描述\n",
    "    sift = cv2.SIFT_create()\n",
    "    bow_img_descriptor_extractor = cv2.BOWImgDescriptorExtractor(sift, flann)        \n",
    "    bow_img_descriptor_extractor.setVocabulary(voc)\n",
    "    \n",
    "    # print(bow_img_descriptor_extractor)\n",
    "    \n",
    "    return bow_img_descriptor_extractor\n",
    "\n",
    "# 提取BOW特征\n",
    "def bow_feature(bow_img_descriptor_extractor, image_list):\n",
    "    # 分别对每个图片提取BOW特征，获得BOW特征列表\n",
    "    feature_bow_list = [] \n",
    "    sift = cv2.SIFT_create()\n",
    "    for i in range(len(image_list)):\n",
    "        image = cv2.cvtColor(image_list[i], cv2.COLOR_BGR2GRAY)\n",
    "        feature_bow = bow_img_descriptor_extractor.compute(image,sift.detect(image))\n",
    "        feature_bow_list.append(feature_bow)\n",
    "    return feature_bow_list\n",
    "\n",
    "\n",
    "def HOG(gre_img):\n",
    "    gray_img = cv2.cvtColor(gre_img,cv2.COLOR_BGR2GRAY)\n",
    "    hog_feature, hog_img = hog(gray_img, orientations=9, \n",
    "                               pixels_per_cell=(6, 6), \n",
    "                               cells_per_block=(3, 3), \n",
    "                               visualize=True, feature_vector=True)\n",
    "    return hog_feature, hog_img\n",
    "\n",
    "# 局部二值特征\n",
    "def LBP(gre_img):\n",
    "    from skimage.feature import local_binary_pattern\n",
    "    method = 'var'\n",
    "    n_points = 8\n",
    "    radius = 4\n",
    "    b, g, r = cv2.split(gre_img)\n",
    "    b = local_binary_pattern(b, n_points, radius, method)\n",
    "    g = local_binary_pattern(g, n_points, radius, method)\n",
    "    r = local_binary_pattern(r, n_points, radius, method)\n",
    "    feature_lbp = cv2.merge((b, g, r))\n",
    "    return feature_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for img, label, img_name in dataset:\n",
    "    print(type(img), type(label), type(img_name))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4440"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "gre_imgs = []\n",
    "sift_features = []\n",
    "for img, label, img_name in dataset:\n",
    "    gre_img = processer(img)\n",
    "    kp, sift_feature = SIFT(gre_img)\n",
    "    gre_imgs.append(gre_img)\n",
    "    sift_features.append(sift_feature)\n",
    "\n",
    "with open(\"sift_features.pkl\", \"wb\") as f:  # 序列化\n",
    "    pkl.dump(sift_features, f) \n",
    "with open(\"gre_img.pkl\", \"wb\") as f:\n",
    "    pkl.dump(gre_imgs, f)\n",
    "len(sift_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4440"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('gre_img.pkl', 'rb') as f:\n",
    "    gre_imgs = pkl.load(f)\n",
    "sift_features = []\n",
    "for img in gre_imgs:\n",
    "    kp, sift_feature = SIFT(img)\n",
    "    sift_features.append(sift_feature)\n",
    "len(sift_features), len(gre_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('gre_img.pkl', 'rb') as f:\n",
    "    gre_imgs = pkl.load(f)\n",
    "with open('sift_features.pkl', 'rb') as f:\n",
    "    sift_features = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_extractor = bow_init(sift_features)\n",
    "all_feature_bow = bow_feature(bow_extractor, gre_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4440"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feature_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_feature_bow.pkl\", \"wb\") as f:  # 序列化\n",
    "    pkl.dump(all_feature_bow, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_bow[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\codes\\python\\machine_learning_design\\src\\maybe_final.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hog_features \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m gre_imgs:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hog_feature, hog_img \u001b[39m=\u001b[39m HOG(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     hog_features\u001b[39m.\u001b[39mappend(hog_feature)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhog_features.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:  \u001b[39m# 序列化\u001b[39;00m\n",
      "\u001b[1;32mf:\\codes\\python\\machine_learning_design\\src\\maybe_final.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mHOG\u001b[39m(gre_img):\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     gray_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(gre_img,cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     hog_feature, hog_img \u001b[39m=\u001b[39m hog(gray_img, orientations\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m                                pixels_per_cell\u001b[39m=\u001b[39;49m(\u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m                                cells_per_block\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m                                visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, feature_vector\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/codes/python/machine_learning_design/src/maybe_final.ipynb#X26sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m hog_feature, hog_img\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\skimage\\_shared\\utils.py:316\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    318\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\skimage\\feature\\_hog.py:260\u001b[0m, in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[0m\n\u001b[0;32m    254\u001b[0m                 centre \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([r \u001b[39m*\u001b[39m c_row \u001b[39m+\u001b[39m c_row \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m                                 c \u001b[39m*\u001b[39m c_col \u001b[39m+\u001b[39m c_col \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m])\n\u001b[0;32m    256\u001b[0m                 rr, cc \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39mline(\u001b[39mint\u001b[39m(centre[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m dc),\n\u001b[0;32m    257\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m dr),\n\u001b[0;32m    258\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m dc),\n\u001b[0;32m    259\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m dr))\n\u001b[1;32m--> 260\u001b[0m                 hog_image[rr, cc] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m orientation_histogram[r, c, o]\n\u001b[0;32m    262\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39mThe fourth stage computes normalization, which takes local groups of\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mcells and contrast normalizes their overall responses before passing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mGradient (HOG) descriptors.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m n_blocks_row \u001b[39m=\u001b[39m (n_cells_row \u001b[39m-\u001b[39m b_row) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hog_features = []\n",
    "for img in gre_imgs:\n",
    "    hog_feature, hog_img = HOG(img)\n",
    "    hog_features.append(hog_feature)\n",
    "with open(\"hog_features.pkl\", \"wb\") as f:  # 序列化\n",
    "    pkl.dump(hog_features, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lbps = []\n",
    "for img in gre_imgs:\n",
    "    feature_lbp = LBP(img)\n",
    "    feature_lbps.append(feature_lbp)\n",
    "with open(\"feature_lbps.pkl\", \"wb\") as f:  # 序列化\n",
    "    pkl.dump(feature_lbps, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
