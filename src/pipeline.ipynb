{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "from processer import equalize, zmIceColor, extractGreen\n",
    "data_path = \"..\\\\dataset\\\\classifer\\\\train\\\\Black-grass\\\\adwstlhujk.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(data_path)\n",
    "cv2.imshow('original', img)\n",
    "# 颜色增强\n",
    "ace_img = zmIceColor(img/255.0, ratio=4, radius=3)\n",
    "cv2.imshow('ace43', ace_img)\n",
    "ace_img  = ace_img * 255\n",
    "ace_img = np.uint8(ace_img)\n",
    "# ace_img = ace_img.astype(np.uint8)\n",
    "gre_img = extractGreen(ace_img, 7)\n",
    "cv2.imshow('gre_img', gre_img)\n",
    "# 创建SIFT特征检测器\n",
    "sift_after = cv2.SIFT_create()\n",
    "# 特征点提取与描述子生成\n",
    "kp, des = sift_after.detectAndCompute(gre_img, None)\n",
    "# kp1, des1 = sift_after.detectAndCompute(gre_img, None)\n",
    "# print(kp == kp1)\n",
    "# print(kp, des)\n",
    "show_img = gre_img.copy()\n",
    "cv2.drawKeypoints(gre_img, kp, show_img)\n",
    "cv2.imshow(\"des\", show_img)\n",
    "# cv2.drawKeypoints(gre_img, kp1, show_img)\n",
    "# cv2.imshow(\"des1\", show_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "datasets_path = \"..\\\\dataset\\\\classifer\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(datasets_path, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 334, 334])\n",
      "torch.Size([1, 3, 307, 307])\n",
      "torch.Size([1, 3, 117, 117])\n",
      "torch.Size([1, 3, 88, 88])\n",
      "torch.Size([1, 3, 78, 78])\n",
      "torch.Size([1, 3, 74, 74])\n",
      "torch.Size([1, 3, 74, 74])\n",
      "torch.Size([1, 3, 73, 73])\n",
      "torch.Size([1, 3, 58, 58])\n",
      "torch.Size([1, 3, 54, 54])\n",
      "torch.Size([1, 3, 51, 51])\n",
      "torch.Size([1, 3, 51, 51])\n",
      "torch.Size([1, 3, 49, 49])\n",
      "torch.Size([1, 3, 49, 49])\n"
     ]
    }
   ],
   "source": [
    "min_shape = 400\n",
    "for x, y in dataloader:\n",
    "    # print(x.shape, y)\n",
    "    # break\n",
    "    if x.shape[-1] <= min_shape:\n",
    "        min_shape = x.shape[-1]\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = []\n",
    "for x, y in dataloader:\n",
    "    shape_list.append(x.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中位数为： 264.0\n",
      "平均数为： 355.815990990991\n",
      "方差为： 91494.17406277082\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "median = statistics.median(shape_list)\n",
    "print(\"中位数为：\", median)\n",
    "avg = statistics.mean(shape_list)\n",
    "print(\"平均数为：\", avg)\n",
    "var = statistics.variance(shape_list)\n",
    "print(\"方差为：\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355.815990990991"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_shape = 0\n",
    "sum_shape = 0\n",
    "num_count = 0\n",
    "for x, y in dataloader:\n",
    "    sum_shape += x.shape[-1]\n",
    "    num_count += 1\n",
    "avg_shape = sum_shape / num_count\n",
    "avg_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579823"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processer(img):\n",
    "    res_img = cv2.resize(img, (256, 256))\n",
    "    # 颜色增强\n",
    "    ace_img = zmIceColor(res_img/255.0, ratio=4, radius=3)\n",
    "    ace_img  = ace_img * 255\n",
    "    ace_img = np.uint8(ace_img)\n",
    "    # 抽绿色\n",
    "    gre_img = extractGreen(ace_img, 7)\n",
    "    return gre_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = \"..\\\\dataset\\\\classifer\\\\train\\\\Small-flowered Cranesbill\\\\zylncejrss.png\"\n",
    "img = cv2.imread(data_path1)\n",
    "gre_img = processer(img)\n",
    "cv2.imshow(\"gre_img\", gre_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建SIFT特征检测器\n",
    "sift_after = cv2.SIFT_create()\n",
    "# 特征点提取与描述子生成\n",
    "kp, des = sift_after.detectAndCompute(gre_img, None)\n",
    "show_img = gre_img.copy()\n",
    "cv2.drawKeypoints(gre_img, kp, show_img)\n",
    "cv2.imshow(\"des\", show_img)\n",
    "# cv2.drawKeypoints(gre_img, kp1, show_img)\n",
    "# cv2.imshow(\"des1\", show_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 128)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "gray_img = cv2.cvtColor(gre_img,cv2.COLOR_BGR2GRAY)\n",
    "# b, g, r = cv2.split(gre_img)\n",
    "# b_feature, b_img = hog(b, orientations=9, pixels_per_cell=(6, 6), cells_per_block=(3, 3), visualize=True, feature_vector=True)\n",
    "# g_feature, g_img = hog(g, orientations=9, pixels_per_cell=(6, 6), cells_per_block=(3, 3), visualize=True, feature_vector=True)\n",
    "# r_feature, r_img = hog(r, orientations=9, pixels_per_cell=(6, 6), cells_per_block=(3, 3), visualize=True, feature_vector=True)\n",
    "# hog_feature, hog_img = hog(gray_img, orientations=9, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
    "hog_feature, hog_img = hog(gray_img, orientations=9, pixels_per_cell=(6, 6), cells_per_block=(3, 3), visualize=True, feature_vector=False)\n",
    "# hog_img = cv2.merge((b_img, g_img, r_img))\n",
    "# cv2.imshow(\"gray_img\", gray_img)\n",
    "cv2.imshow(\"hog_img\", hog_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3, 3, 9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gre_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 334, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "method = 'var'\n",
    "n_points = 8\n",
    "radius = 4\n",
    "b, g, r = cv2.split(gre_img)\n",
    "b = local_binary_pattern(b, n_points, radius, method)\n",
    "g = local_binary_pattern(g, n_points, radius, method)\n",
    "r = local_binary_pattern(r, n_points, radius, method)\n",
    "feature_lbp = cv2.merge((b, g, r))\n",
    "cv2.imshow(\"feature_lbp\", feature_lbp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_lbp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.333336   29.666668    0.         ... 14.666667    3.6666667\n",
      "  25.333334  ]\n",
      " [ 0.          0.          0.         ...  0.33333334  1.\n",
      "   6.3333335 ]\n",
      " [17.57143    11.142858    1.8571429  ...  4.857143    2.857143\n",
      "   6.1428576 ]\n",
      " ...\n",
      " [12.5         0.          0.         ... 14.          0.\n",
      "   0.5       ]\n",
      " [ 0.          0.          0.         ... 10.         23.5\n",
      "  28.        ]\n",
      " [ 1.         29.         92.         ...  0.          0.\n",
      "   0.        ]] <class 'numpy.ndarray'> (20, 128)\n"
     ]
    }
   ],
   "source": [
    "bow_kmeans_trainer = cv2.BOWKMeansTrainer(20)\n",
    "bow_kmeans_trainer.add(des)\n",
    "# k-means返回词汇字典(聚类中心)\n",
    "voc = bow_kmeans_trainer.cluster()\n",
    "print(voc, type(voc),voc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.FlannBasedMatcher 0000012443197530>\n"
     ]
    }
   ],
   "source": [
    "# FLANN匹配  \n",
    "# algorithm用来指定匹配所使用的算法，可以选择的有LinearIndex、KTreeIndex、KMeansIndex、CompositeIndex和AutotuneInde\n",
    "# 这里选择的是KTreeIndex(使用kd树实现最近邻搜索)\n",
    "flann_params = dict(algorithm=1,tree=5)\n",
    "flann = cv2.FlannBasedMatcher(flann_params,{})\n",
    "\n",
    "print(flann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.BOWImgDescriptorExtractor 00000124431941F0>\n"
     ]
    }
   ],
   "source": [
    "#初始化bow提取器(设置词汇字典),用于提取每一张图像的BOW特征描述\n",
    "sift = cv2.SIFT_create()\n",
    "bow_img_descriptor_extractor = cv2.BOWImgDescriptorExtractor(sift, flann)        \n",
    "bow_img_descriptor_extractor.setVocabulary(voc)\n",
    "\n",
    "print(bow_img_descriptor_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01754386, 0.06432749, 0.0497076 , 0.07602339, 0.0497076 ,\n",
       "        0.00877193, 0.03508772, 0.03508772, 0.00877193, 0.05847953,\n",
       "        0.06140351, 0.02923977, 0.01461988, 0.00877193, 0.05555556,\n",
       "        0.03508772, 0.19590643, 0.0497076 , 0.12280702, 0.02339181]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_bow_list = [] \n",
    "sift = cv2.SIFT_create()\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "feature_bow = bow_img_descriptor_extractor.compute(image, sift.detect(image))\n",
    "feature_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class BOW(object):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        #创建一个SIFT对象  用于关键点提取\n",
    "        self.feature_detector  = cv2.xfeatures2d.SIFT_create()\n",
    "        #创建一个SIFT对象  用于关键点描述符提取 \n",
    "        self.descriptor_extractor = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    def path(self,cls,i):\n",
    "        \\'\\'\\'\n",
    "        用于获取图片的全路径 \n",
    "        \\'\\'\\'\n",
    "        return \\'%s/%s/%s.%d.jpg\\'%(self.train_path,cls,cls,i+1)\n",
    "\n",
    "    def fit(self,train_path,k):\n",
    "        \\'\\'\\'\n",
    "        开始训练\n",
    "        \n",
    "        args：\n",
    "            train_path：训练集图片路径  我们使用的数据格式为 train_path/dog/dog.i.jpg  train_path/cat/cat.i.jpg\n",
    "            k：k-means参数k\n",
    "        \\'\\'\\'\n",
    "        self.train_path = train_path        \n",
    "        \n",
    "        #FLANN匹配  参数algorithm用来指定匹配所使用的算法，可以选择的有LinearIndex、KTreeIndex、KMeansIndex、CompositeIndex和AutotuneIndex，这里选择的是KTreeIndex(使用kd树实现最近邻搜索)\n",
    "        flann_params = dict(algorithm=1,tree=5)\n",
    "        flann = cv2.FlannBasedMatcher(flann_params,{})\n",
    "        \n",
    "        #创建BOW训练器，指定k-means参数k   把处理好的特征数据全部合并，利用聚类把特征词分为若干类，此若干类的数目由自己设定，每一类相当于一个视觉词汇\n",
    "        bow_kmeans_trainer = cv2.BOWKMeansTrainer(k)\n",
    "        \n",
    "        pos = \\'dog\\'\n",
    "        neg = \\'cat\\'\n",
    "        \n",
    "        #指定用于提取词汇字典的样本数\n",
    "        length = 10\n",
    "        #合并特征数据  每个类从数据集中读取length张图片(length个狗,length个猫)，通过聚类创建视觉词汇\n",
    "        for i in range(length):\n",
    "            bow_kmeans_trainer.add(self.sift_descriptor_extractor(self.path(pos,i)))\n",
    "            bow_kmeans_trainer.add(self.sift_descriptor_extractor(self.path(neg,i)))\n",
    "\n",
    "        #进行k-means聚类，返回词汇字典 也就是聚类中心\n",
    "        voc = bow_kmeans_trainer.cluster()\n",
    "        \n",
    "        #输出词汇字典  <class \\'numpy.ndarray\\'> (40, 128)\n",
    "        print(type(voc),voc.shape)\n",
    "        \n",
    "        #初始化bow提取器(设置词汇字典),用于提取每一张图像的BOW特征描述\n",
    "        self.bow_img_descriptor_extractor = cv2.BOWImgDescriptorExtractor(self.descriptor_extractor,flann)        \n",
    "        self.bow_img_descriptor_extractor.setVocabulary(voc)\n",
    "        \n",
    "        \n",
    "        #创建两个数组，分别对应训练数据和标签，并用BOWImgDescriptorExtractor产生的描述符填充\n",
    "        #按照下面的方法生成相应的正负样本图片的标签 1：正匹配  -1：负匹配\n",
    "        traindata,trainlabels = [],[]\n",
    "        for i in range(400):   #这里取200张图像做训练\n",
    "            traindata.extend(self.bow_descriptor_extractor(self.path(pos,i)))\n",
    "            trainlabels.append(1)\n",
    "            traindata.extend(self.bow_descriptor_extractor(self.path(neg,i)))\n",
    "            trainlabels.append(-1)\n",
    "         \n",
    "        #创建一个SVM对象    \n",
    "        self.svm = cv2.ml.SVM_create()\n",
    "        #使用训练数据和标签进行训练\n",
    "        self.svm.train(np.array(traindata),cv2.ml.ROW_SAMPLE,np.array(trainlabels))\n",
    "\n",
    "\n",
    "    def predict(self,img_path):\n",
    "        \\'\\'\\'\n",
    "        进行预测样本   \n",
    "        \\'\\'\\'\n",
    "        #提取图片的BOW特征描述\n",
    "        data = self.bow_descriptor_extractor(img_path)\n",
    "        res = self.svm.predict(data)\n",
    "        print(img_path,\\'\\t\\',res[1][0][0])\n",
    "        \n",
    "        #如果是狗 返回True\n",
    "        if res[1][0][0] == 1.0:\n",
    "            return True\n",
    "        #如果是猫，返回False\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "     \n",
    "    def sift_descriptor_extractor(self,img_path):\n",
    "        \\'\\'\\'\n",
    "        特征提取：提取数据集中每幅图像的特征点，然后提取特征描述符，形成特征数据(如：SIFT或者SURF方法)；\n",
    "        \\'\\'\\'\n",
    "        im = cv2.imread(img_path,0)     \n",
    "        return self.descriptor_extractor.compute(im,self.feature_detector.detect(im))[1]  \n",
    "    \n",
    "    \n",
    "    def bow_descriptor_extractor(self,img_path):\n",
    "        \\'\\'\\'\n",
    "        提取图像的BOW特征描述(即利用视觉词袋量化图像特征)\n",
    "        \\'\\'\\'\n",
    "        im = cv2.imread(img_path,0)\n",
    "        return self.bow_img_descriptor_extractor.compute(im,self.feature_detector.detect(im))\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \\'__main__\\':\n",
    "    #测试样本数量，测试结果\n",
    "    test_samples = 100\n",
    "    test_results = np.zeros(test_samples,dtype=np.bool)\n",
    "    \n",
    "    #训练集图片路径  狗和猫两类  进行训练\n",
    "    train_path = \\'./data/cat_and_dog/data/train\\'\n",
    "    bow = BOW()\n",
    "    bow.fit(train_path,40)\n",
    "    \n",
    "    \n",
    "    #指定测试图像路径\n",
    "    for index in range(test_samples):\n",
    "        dog = \\'./data/cat_and_dog/data/train/dog/dog.{0}.jpg\\'.format(index)\n",
    "        dog_img = cv2.imread(dog)    \n",
    "    \n",
    "        #预测\n",
    "        dog_predict = bow.predict(dog)    \n",
    "        test_results[index] = dog_predict\n",
    "        \n",
    "    #计算准确率\n",
    "    accuracy = np.mean(test_results.astype(dtype=np.float32)) \n",
    "    print(\\'测试准确率为：\\',accuracy)\n",
    "        \n",
    "    #可视化最后一个    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX    \n",
    "    if test_results[0]:\n",
    "        cv2.putText(dog_img,\\'Dog Detected\\',(10,30),font,1,(0,255,0),2,cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow(\\'dog_img\\',dog_img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
